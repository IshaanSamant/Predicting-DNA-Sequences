{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TF_net.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufBVp5_EbvHJ","executionInfo":{"status":"ok","timestamp":1618434068200,"user_tz":-120,"elapsed":3390,"user":{"displayName":"Vittorio Pipoli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjl5ImUIdl3WuIzbzHHEpYUFFgioDc_I1zwr7-FYw=s64","userId":"13197758426377553487"}},"outputId":"d196d242-9dab-4228-80b0-cef6f2aa2c80"},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from scipy import stats\n","from keras.models import Model, load_model\n","import numpy as np\n","import datetime, os\n","%pylab inline\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from IPython.display import display, Image\n","from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n","from keras import backend as K\n","\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Populating the interactive namespace from numpy and matplotlib\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nos4dWnlb7MX"},"source":["class projTFNet:\n","    def __init__(   self,\n","                    checkpoint_dir=\"\",\n","                    model_type=\"TF\",\n","                    n_epochs=10, \n","                    batch_size=32, \n","                    learning_rate=5e-4,\n","                    momentum=0.9,\n","                    lr_reduction_epoch=None,\n","                    shuffle=True,\n","                    logdir=None,\n","                    patience=30):\n","        \n","        self.checkpoint_dir=checkpoint_dir\n","        self.model_type=model_type\n","        self.n_epochs = n_epochs\n","        self.batch_size = batch_size\n","        self.learning_rate = learning_rate\n","        self.momentum = momentum\n","        self.lr_reduction_epoch = lr_reduction_epoch\n","        self.shuffle=shuffle\n","        self.logdir=logdir\n","        self.patience=patience\n","\n","        self._build_model()\n","\n","    def _build_model(self):\n","        if self.model_type == \"TF\":\n","            input1 = layers.Input(shape=(181))\n","            x = layers.Dense(64, activation=\"relu\")(input1)\n","            x = layers.Dropout(0.00099)(x)\n","            x = layers.Dense(2, activation=\"relu\")(x)\n","            x = layers.Dropout(0.01546)(x)\n","            output = layers.Dense(1, activation=\"linear\")(x)\n","\n","            print(\"model built\")\n","            self.model = keras.Model(\n","                inputs=[input1],\n","                outputs=[output],\n","                )\n","            self.model.summary()\n","            img = keras.utils.plot_model(self.model, \"multi_input_and_output_model.png\", show_shapes=True)\n","            display(img)\n","\n","\n","    def train_model(self, x_train, y_train, x_val=None, y_val=None, TPU=False):\n","        #train test split\n","        if x_val is None:\n","            x_train, y_train, x_val, y_val = self._split_validation_data(x_train, y_train, 0.1)\n","        #optimizer\n","        # optimizer = tf.keras.optimizers.Adam(lr=self.learning_rate)\n","        optimizer = tf.keras.optimizers.SGD(lr=self.learning_rate, momentum=self.momentum)\n","        self.model.compile(optimizer=optimizer, loss='mae')\n","        history = tf.keras.callbacks.History()\n","        check_cb = ModelCheckpoint(os.path.join(f\"Saved_Models/checkpoint/{self.checkpoint_dir}\", f'bestmodel_CNN1D_{self.model_type}'), monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","        earlystop_cb = EarlyStopping(monitor='val_loss', patience=self.patience, verbose=1, mode='min', restore_best_weights=TPU)\n","\n","        if TPU == True:\n","            if self.lr_reduction_epoch is not None:\n","                scheduler_callback = tf.keras.callbacks.LearningRateScheduler(self.lr_scheduler, verbose=1)\n","                callbacks = [history,\n","                                scheduler_callback,\n","                                earlystop_cb] \n","            else:\n","                callbacks = [history,\n","                                earlystop_cb]\n","        else:\n","            if self.lr_reduction_epoch is not None:\n","                scheduler_callback = tf.keras.callbacks.LearningRateScheduler(self.lr_scheduler, verbose=1)\n","                callbacks = [history,\n","                                check_cb,\n","                                scheduler_callback,\n","                                earlystop_cb]\n","            else:\n","                callbacks = [history,\n","                                check_cb,\n","                                earlystop_cb]\n","        if self.logdir is not None:\n","            tensorboard_callback = tf.keras.callbacks.TensorBoard(self.logdir, \n","                                                        histogram_freq=1,\n","                                                        write_grads=True,\n","                                                        update_freq='epoch')\n","            callbacks.append(tensorboard_callback)\n","\n","        self.model.fit(x=x_train, \n","            y=y_train, \n","            shuffle=self.shuffle,\n","            epochs=self.n_epochs,\n","            batch_size=self.batch_size,\n","            validation_data=(x_val, y_val),\n","            callbacks=callbacks)\n","\n","        self.history = history\n","        plt.rcParams[\"figure.figsize\"] = (20,9)\n","        pyplot.plot(history.history['loss'])\n","        pyplot.plot(history.history['val_loss'])\n","        pyplot.hlines(0.4, 0, len(history.history['loss']) , alpha = 0.2)\n","        pyplot.hlines(0.42, 0, len(history.history['loss']) , alpha = 0.2 )\n","        pyplot.title('model train vs validation loss')\n","        pyplot.ylabel('loss')\n","        pyplot.xlabel('epoch')\n","        pyplot.legend(['train', 'validation'], loc='upper right')\n","        pyplot.show()\n","        \n","    def evaluate(self, x, y):\n","        predictions = self.model.predict(x).flatten()\n","        slope, intercept, r_value, p_value, std_err = stats.linregress(predictions, y)\n","        print('Test R^2 = %.3f' % r_value**2)\n","        return r_value**2\n","\n","    def evaluate_best(self, x, y, TPU=False):\n","        if TPU is False:\n","            best_file = os.path.join(f\"Dataset/checkpoint/{self.checkpoint_dir}\", f'bestmodel_CNN1D_{self.model_type}')\n","            model = load_model(best_file)\n","            predictions = model.predict(x).flatten()\n","        else:\n","            predictions = self.model.predict(x).flatten()\n","        slope, intercept, r_value, p_value, std_err = stats.linregress(predictions, y)\n","        print('Test R^2 = %.3f' % r_value**2)\n","        return r_value**2\n","\n","    def plot_kde(self, x, y, TPU=False):\n","        if TPU is False:\n","            best_file = os.path.join(f\"Dataset/checkpoint/{self.checkpoint_dir}\", f'bestmodel_CNN1D_{self.model_type}')\n","            model = load_model(best_file)\n","            predictions = model.predict(x).flatten()\n","        else:\n","            predictions = self.model.predict(x).flatten()\n","        df = pd.DataFrame({\"predictions\":predictions, \"true\":y})\n","        ax = sns.displot(data=df, kde=True)\n","        plt.xlabel(\"Labels\")\n","        plt.show()\n","        \n","    def plot_train(self):\n","        history = self.history\n","        plt.rcParams[\"figure.figsize\"] = (20,9)\n","        pyplot.plot(history.history['loss'])\n","        pyplot.plot(history.history['val_loss'])\n","        pyplot.hlines(0.4, 0, len(history.history['loss']) , alpha = 0.2)\n","        pyplot.hlines(0.42, 0, len(history.history['loss']) , alpha = 0.2 )\n","        pyplot.title('model train vs validation loss')\n","        pyplot.ylabel('loss')\n","        pyplot.xlabel('epoch')\n","        pyplot.legend(['train', 'validation'], loc='upper right')\n","        pyplot.show()\n","\n","    def plot_r2(self, x, y, TPU=False):\n","        from matplotlib import cm\n","        if TPU == False:\n","            best_file = os.path.join(f\"Dataset/checkpoint/{self.checkpoint_dir}\", f'bestmodel_CNN1D_{self.model_type}')\n","            model = load_model(best_file)\n","            predictions = model.predict(x).flatten()\n","        else:\n","            predictions = self.model.predict(x).flatten()\n","        slope, intercept, r_value, p_value, std_err = stats.linregress(predictions, y)\n","\n","        viridis = cm.get_cmap('autumn', 12)\n","        diff = y - predictions\n","        diff = np.abs(diff)\n","\n","        ### plt size\n","        plt.rcParams[\"figure.figsize\"] = (10,9)\n","        ### plt fontsize\n","        plt.rcParams.update({'font.size': 16})\n","\n","        ### set title\n","        plt.title(\"Expression Scatterplot\")\n","        ### plot\n","        bis = np.arange(-1.5, 3, 2)\n","        plt.plot(bis, bis,  f\"b\", alpha=0.3)\n","        for p, yi, c in zip(predictions, y, diff):\n","            plt.plot(p, yi,  f\".\", markersize=10, color=viridis((1.0-c)/1.1))\n","        ### set ticks\n","        plt.xticks([i for i in range(-1, 4)])\n","        plt.yticks([i for i in range(-1, 4)])\n","        ### set labels\n","        plt.xlabel(\"Predicted expression level\")\n","        plt.ylabel(\"Median expression level\")\n","        ### create legend\n","        plt.legend(loc=\"upper right\", title=f\"r2 = %.3f\\n n = 1000\" % r_value**2)\n","        ### set ylim\n","        plt.ylim((-1.5,3))\n","        plt.xlim((-1.5,3))\n","        ### grid\n","        plt.grid(alpha=0.5)\n","        ### save\n","        # if self.save:\n","        #     plt.savefig(f\"{self.dir}{self.filename}.png\")\n","        ### show\n","        plt.show()\n","\n","\n","    @staticmethod\n","    def _split_validation_data(x, y, validation_split):\n","        rand_indexes = np.random.permutation(x.shape[0])\n","        x = x[rand_indexes]\n","        y = y[rand_indexes]\n","        x_validation = x[:int(len(x) * validation_split)]\n","        y_validation = y[:int(len(x) * validation_split)]\n","        x_train = x[int(len(x) * validation_split):]\n","        y_train = y[int(len(x) * validation_split):]\n","        return x_train, y_train, x_validation, y_validation\n","\n","    def lr_scheduler(self, epoch, lr):\n","        if epoch == self.lr_reduction_epoch:\n","            return lr * 0.1\n","        else:\n","            return lr "],"execution_count":null,"outputs":[]}]}